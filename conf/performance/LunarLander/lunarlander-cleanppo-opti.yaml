# @package _global_
# Changes specified in this config should be interpreted as relative to the _global_ package.
defaults:
  - override /algorithm: cleanppo

eval_after_n_steps: 2000
# The max. number of training epochs to run. One epoch consists of 'eval_after_n_steps' actions.
n_epochs: 100
hyperopt_criterion: 'eval/mean_reward'

algorithm:
  gamma: 0.99
  gae_lambda: 0.95
  batch_size: 64
hydra:
  sweeper:
    study_name: cleanppo_lunar_lander_env_opti
    max_trials: 100
    n_jobs: 10
    direction: maximize
    max_duration_minutes: 600
    min_trials_per_param: 2
    max_trials_per_param: 5
    search_space:
      ++algorithm.learning_rate:
        type: float
        low: 0.00005
        high: 0.005
        log: true
      ++algorithm.gamma:
        type: float
        low: 0.95
        high: 0.99
      ++algorithm.gae_lambda:
        type: float
        low: 0.95
        high: 0.99
      ++algorithm.ent_coef:
        type: float
        low: 0.005
        high: 0.05
      ++env_kwargs.gravity:
        type: float
        low: -10.0
        high: 0.0
        step: 5.0
      ++env_kwargs.wind_power:
        type: float
        low: 0.0
        high: 20.0
        step: 10.0
      ++env_kwargs.turbulence_power:
        type: float
        low: 0.0
        high: 2.0
        step: 1.0
